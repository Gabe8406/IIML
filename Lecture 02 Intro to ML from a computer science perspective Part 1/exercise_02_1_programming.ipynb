{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Machine Learning -- An Interdisciplinary Introduction\n",
    "\n",
    "## Classification\n",
    "\n",
    "A classification task is to assign a specific class to a given sample.\n",
    "One of the most simple classification algorithms is the k-nearest-neighbor classifier.\n",
    "Given a training set of samples \n",
    "$$X = \\{(\\vec x_n, t_n) \\mid 0\\leq n<N \\}$$\n",
    "we can simply store all the samples and their labels.\n",
    "For a given test sample $\\vec x$, we iterate through the training set and compute the labels of the $K$ neaeast neighbors.\n",
    "That is, we compute the distances to all training set samples:\n",
    "$$D = \\{\\|\\vec x_n- \\vec x\\|^2 \\mid 0\\leq n<N\\}$$\n",
    "and select those samples with the minimum distances.\n",
    "Then, we assign the class to the sample that appears most often in the nearest neighbors.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We make use of the [Iris Flower dataset](https://archive.ics.uci.edu/ml/datasets/iris).\n",
    "The dataset contains three different types of iris flowers, where the length and the width of sepal and pedal of the flowers are measured.\n",
    "Let us first download the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# load the dataset\n",
    "dataset_file = \"iris.data\"\n",
    "if not os.path.exists(dataset_file):\n",
    "  urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", dataset_file)\n",
    "  print (\"Downloaded datafile\", dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us read the data from file. \n",
    "Note that the whole dataset is contained in one file.\n",
    "The labels are given as text, which we translate into a 0-based index, which our code can handle better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "\n",
    "# read the data\n",
    "with open(dataset_file, 'r') as f:\n",
    "  reader = csv.reader(f, delimiter=\",\")\n",
    "  class_names = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
    "  # read all data\n",
    "  X, T = [], []\n",
    "  for splits in reader:\n",
    "    if splits:\n",
    "      X.append([float(x) for x in splits[:4]])\n",
    "      T.append(class_names.index(splits[4]))\n",
    "\n",
    "# We turn the data into torch tensors for easier handling\n",
    "X = torch.tensor(X)\n",
    "T = torch.tensor(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split off training and testing data.\n",
    "Ideally, we would also define a validation set, but for the purpose of this small exercise, we abstain from doing so.\n",
    "\n",
    "Let us first have a look into the structure of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we print the whole list of labels\n",
    "print(T)\n",
    "# count how often each of the three labels exist in the dataset\n",
    "for t in range(3):\n",
    "  print(t, torch.sum(T==t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, they are sorted, and we have 50 of each label.\n",
    "Let's split 25 samples of each class for training, and the other 25 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the number of training samples per class that we use\n",
    "split = 25\n",
    "\n",
    "# split them into training and test set\n",
    "train_indexes = list(range(split)) + list(range(50,50+split)) + list(range(100,100+split))\n",
    "test_indexes = list(range(split,50)) + list(range(50+split,100)) + list(range(100+split,150))\n",
    "\n",
    "# Assign the training and test data and labels\n",
    "train_data = X[train_indexes]\n",
    "train_labels = T[train_indexes]\n",
    "test_data = X[test_indexes]\n",
    "test_labels = T[test_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "Let's visualize our data, as far as we can.\n",
    "We plot each two dimensions of our data, with colors corresponding to the original classes, which shows that these samples cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.figure(figsize=(10,5))\n",
    "for i in range(2):\n",
    "  # we create two horizontally aligned subplots\n",
    "  pyplot.subplot(1,2,i+1)\n",
    "  # select dimensions 1 and 2 or 3 and 4 for visualization (remember 0-based indexing)\n",
    "  d1, d2 = 2*i,2*i+1\n",
    "  # plot all samples of each class in a separate color\n",
    "  pyplot.plot(X[T==0,d1], X[T==0,d2], \"ro\", label=class_names[0])\n",
    "  pyplot.plot(X[T==1,d1], X[T==1,d2], \"g+\", label=class_names[1])\n",
    "  pyplot.plot(X[T==2,d1], X[T==2,d2], \"bx\", label=class_names[2])\n",
    "  # make the plot more beautiful by adding \n",
    "  pyplot.xlabel(f\"$x_{d1+1}$\")\n",
    "  pyplot.ylabel(f\"$x_{d2+1}$\")\n",
    "  pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: K Nearest Neighbor Function\n",
    "\n",
    "Write a function that computes the $K$ nearest neighbors from the training set.\n",
    "This function takes the entire training set `X` and its according labels `T`. \n",
    "Additionally, it takes one test `sample` that should be classified, and the number of nearest neighbors `K` to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(X, T, sample, K=5):\n",
    "  \"\"\"Predicts the class for the given sample using the k-nearest-neighbor algorithm.\n",
    "  For each training sample (x,t), it computes the Euclidean distance to the test sample.\n",
    "  The classes of the K nearest samples are considered, and the test sample is assigned to the majority class.\n",
    "\n",
    "  Parameters:\n",
    "  X: torch.tensor(float) in shape (N,D): The training set samples where N is the number of samples and D is the sample dimensionality.\n",
    "  T: torch.tensor(int) in shape (N): The training set labels representing the target classes.\n",
    "  sample: torch.tensor(float) in shape (D): The current test sample\n",
    "  K: int: The number of nearest neighbors to consider\n",
    "\n",
    "  Returns:\n",
    "  int: the predcicted class index for the test sample\n",
    "  \"\"\"\n",
    "  # compute distances between sample and training points\n",
    "  distances = ...\n",
    "\n",
    "  # sort the distances and get the indexes of the K nearest samples\n",
    "  indexes = ...\n",
    "\n",
    "  # get the labels from those samples\n",
    "  labels = ...\n",
    "\n",
    "  # count the labels, i.e., how often was a class predicted\n",
    "  counts = ...\n",
    "\n",
    "  # return the label of the maximum count\n",
    "  return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Correct Classification\n",
    "\n",
    "Select a value of $K$ of your choice.\n",
    "Classify all test set samples and count how often the correct class was predicted.\n",
    "Which value of $K$ works best in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all of our test samples and compute its class prediction\n",
    "predictions = []\n",
    "for sample in test_data:\n",
    "  # compute class prediction for current test sample\n",
    "  prediction = ...\n",
    "  # store it in our list\n",
    "  predictions.append(prediction)\n",
    "# turn them imto torch tensors for further processing\n",
    "predictions = torch.tensor(predictions)\n",
    "\n",
    "# compute the total number of correct classifications, i.e., where the prediction and the test label are equal\n",
    "correct = ...\n",
    "# obtain the total number of test samples\n",
    "total = ...\n",
    "\n",
    "print(f\"Classified {correct} of {total} samples correctly, accuracy is {correct/total*100:3.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the total number of correctly classified samples might not be sufficient.\n",
    "It is better if we could also see, which classes are confused with which other classes.\n",
    "For this purpose, we can plot a confusion matrix.\n",
    "The easiest way of plotting this is by using the `sklearn.metrics.ConfusionMatrixDisplay.from_predictions` function.\n",
    "\n",
    "## Task 3: Confusion Matrix Plot\n",
    "\n",
    "Plot a confusion matrix between the correct labels and the predicted outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Discuss Issues of k-Nearest Neighbors\n",
    "\n",
    "Problems of the k-nearest neighbor approach include the following:\n",
    "\n",
    "* Selection of $K$: how can we find out how many neighbors we need?\n",
    "* Tie-breaker: what happens when neighbor counts from two classes are identical and maximal?\n",
    "* Training data selection: which training samples should we keep, and which samples might be superfluous?\n",
    "\n",
    "Discuss possible solutions to these issues.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a29cabff5744fce69e08a959ab87b9e77a9f67b498d08783caa8c3bb16f23a00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
