{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppW_8VDuReSG"
      },
      "source": [
        "# Programming Exercise Week 9: Toxicity of molecules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WiUZzDSZrBo"
      },
      "source": [
        "## Part A: Preparations\n",
        "\n",
        "Run the following code to import some tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1DWWhW_GyCB",
        "outputId": "0c244ae4-1f08-45e3-865c-ac20402fe223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 29.5 MB 60.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "\n",
        "# Package for loading the data\n",
        "import pandas as pd\n",
        "\n",
        "# Package of functions creating iterators for efficient looping\n",
        "import itertools \n",
        "\n",
        "# Package to (amongst other things) draw and plot molecules in the SMILES format (see below)\n",
        "!pip install rdkit-pypi -qqq\n",
        "import rdkit.Chem\n",
        "import rdkit.Chem.Draw\n",
        "\n",
        "# Package to shuffle and split the dataset\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LxaQ6WNcpXI"
      },
      "source": [
        "---\n",
        "\n",
        "In this exercise we will study the toxicity of molecules.\n",
        "Molecules will be described using the simplified molecular input line entry system (SMILES). This system allows to describe the structure of chemical species in the form of a line notation, making it suited for a machine learning approach. \n",
        "\n",
        "---\n",
        "\n",
        "**The basic rules for SMILES are:**\n",
        "\n",
        "* Atom types are represented by their atomic symbols, upper case letters represent aliphatic atoms, lower case letters represented aromatic atoms, hydrogens are often stripped away, since those can be inferred from atom type and connectivity.\n",
        "\n",
        "* Bonds are only represented if needed:\n",
        "\n",
        " $\\text{-}$ : single bond (CC and C-C are the same, since single bonds are used by default)\n",
        "\n",
        " = : double bond (C=C-C=C and cccc are the same)\n",
        " \n",
        " $\\#$ : triple bond\n",
        "\n",
        "* Ring opening and closures are represented with numbers: \n",
        " \n",
        " c1ccccc1 - benzene\n",
        "\n",
        "* Substituents leaving a chain or ring are represented with brackets:\n",
        "\n",
        " c1cc(C)ccc1 - methyl-substituted benzene.\n",
        "\n",
        " CC(F)(Br)Cl - ethane substituted with fluorine, chlorine and bromine\n",
        "\n",
        "(More detailed rules, not necessary for our exercise, can be found here: https://www.daylight.com/dayhtml/doc/theory/theory.smiles.html)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhjVeZDG_1Xa"
      },
      "source": [
        "**1a)** With the following commands one can draw a 2d-representation of the molecule using its SMILE representation. Experiment with them to understand how SMILES work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "11yIaNQ73weu",
        "outputId": "d0fea237-c0c9-402e-cf2f-1c5f5652c9ed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=200x200 at 0x7F12F8EBAF50>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m=rdkit.Chem.MolFromSmiles('c1cc(C)ccc1')\n",
        "rdkit.Chem.Draw.MolToImage(m, size=(200, 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWTjltZR5A1-"
      },
      "source": [
        "**1b)** With the rules from above, you should be able to create for example the SMILES for acetylsalicylic acid, the active ingredient of Aspirin:\n",
        "![Aspirin-skeletal.svg](data:image/svg+xml;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CRrPSM26Ibs"
      },
      "outputs": [],
      "source": [
        "# Write the SMILES for acetylsalicylic acid and check its 2D-representation\n",
        "\n",
        "\"*** YOUR CODE HERE ***\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoVA-nYQ74YQ"
      },
      "source": [
        "---\n",
        "\n",
        "We now load the toxicity dataset from the TOX21 program (https://github.com/filipsPL/tox21_dataset/tree/master/compounds) and save the SMILES in the array 'smiles', and the activities in the array 'toxicity'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKj3GUA0LobC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# load the data from the 'sr-are' dataset\n",
        "datapd = pd.read_csv('https://raw.githubusercontent.com/filipsPL/tox21_dataset/master/compounds/sr-are.tab',sep=\"\\t\")\n",
        "data=datapd.to_numpy()\n",
        "\n",
        "# define smiles and toxicity\n",
        "smiles=data[:,1]\n",
        "toxicity=torch.tensor(np.array(data[:,2],dtype = float))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4swsj97fEVkU"
      },
      "source": [
        "**2)** Check the SMILES and toxicity of the first 5 compounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6eji9EHFvFG"
      },
      "outputs": [],
      "source": [
        "# print out the SMILES of the first 5 compounds\n",
        "\n",
        "\"*** YOUR CODE HERE ***\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ_dxfFFDwtU"
      },
      "outputs": [],
      "source": [
        "# print out the activity of the first 5 compounds\n",
        "\n",
        "\"*** YOUR CODE HERE ***\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-ng6dyhKTS7"
      },
      "source": [
        "---\n",
        "\n",
        "In order to make the data usable for a neural network we have to generate a mapping from characters to integers and vice versa.\n",
        "\n",
        "We first create a sorted list of the characters used in the SMILES of our dataset, stored in 'unique_chars'. We then create a mapping between this list and the integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_g9jwzgKXaT"
      },
      "outputs": [],
      "source": [
        "# list of characters\n",
        "# itertools.chain makes an iterator that returns elements from the first iterable until it is exhausted, \n",
        "# then proceeds to the next iterable, until all of the iterables are exhausted. \n",
        "# Consecutive sequences are treated as a single sequence.\n",
        "unique_chars = list(set(itertools.chain.from_iterable(smiles)))\n",
        "\n",
        "# Add an end character as the first element in the dictionary\n",
        "unique_chars.insert(0, 'E')\n",
        "\n",
        "# character to integer dictionary\n",
        "# allows fast mapping of a character in smiles to the representative integer\n",
        "char_to_int = dict((c, i) for i, c in enumerate(unique_chars))\n",
        "\n",
        "# integer to character dictionary\n",
        "# allows fast mapping of a representative integer to the smiles character\n",
        "int_to_char = dict((i, c) for i, c in enumerate(unique_chars))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0NOnDFWjmDA"
      },
      "source": [
        "**3a)** Check that the dictionary is well-defined. Which integer belongs to 'C'?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2G6VHoLMFT5"
      },
      "outputs": [],
      "source": [
        "# print out the dictionary\n",
        "\n",
        "\"*** YOUR CODE HERE ***\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9kiDtXki4L5"
      },
      "outputs": [],
      "source": [
        "# find the integer belonging to 'C'\n",
        "\n",
        "intC = ...\n",
        "print('integer belonging to C: ', intC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sumXf2EBpFHm"
      },
      "source": [
        "**3b)** How many unique characters do we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GJGXUnMOhNU"
      },
      "outputs": [],
      "source": [
        "# find the number of unique characters\n",
        "\n",
        "mapping_size = ...\n",
        "print (\"Size of the character to integer dictionary is: \", mapping_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaBVQIrJaU5w"
      },
      "source": [
        "---\n",
        "\n",
        "Now we can encode the SMILES sequences using the dictionary. \n",
        "\n",
        "The resulting dimensions of the encoded data array should be (number of SMILES sequences, length of the longest sequence, length of dictionary). \n",
        "\n",
        "The last dimension is used as a one-hot-encoding of the respective character. \n",
        "\n",
        "For example the indices [11,3,5] correspond to position number 3 of sequence number 11 and to character number 5 in the dictionary: the value in the array is \"1\" if the character is at this position of the sequence, otherwise \"0\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb8mQ8uB8O4K"
      },
      "source": [
        "**4a)** First we need the number of SMILES sequences and the length of the longest sequence: \n",
        "\n",
        "find and store them in the variables 'n_seq' and 'longest'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w112ZK2SAjau"
      },
      "outputs": [],
      "source": [
        "# number of SMILES sequences\n",
        "\n",
        "n_seq = ... \n",
        "print('number of SMILES sequences: ', n_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-EZD5SWkkJ4"
      },
      "outputs": [],
      "source": [
        "# longest SMILES sequence\n",
        "\n",
        "longest = ...\n",
        "print('length of the longest sequence: ', longest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ63zzblEzxh"
      },
      "source": [
        "The following routine returns the encoded data array, as described above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfUVCcheacRX"
      },
      "outputs": [],
      "source": [
        "# routine to encode the dataset\n",
        "def gen_data(dataset_of_smiles_seq,char_to_int_dict,number_of_seq,length_of_longest_seq,number_of_unique_chars):\n",
        "    \n",
        "    one_hot =  torch.zeros((number_of_seq,length_of_longest_seq,number_of_unique_chars),dtype=torch.float)\n",
        "    for i,smile in enumerate(dataset_of_smiles_seq):\n",
        "        #encode the chars\n",
        "        for j,k in enumerate(smile):\n",
        "            one_hot[i,j,char_to_int_dict[k]] = 1\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAEr6pS8I8eO"
      },
      "source": [
        "**4b)** Use now this routine with appropriate inputs arrays and variables to encode our SMILES dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThDfspRubseT"
      },
      "outputs": [],
      "source": [
        "# encode the dataset\n",
        "\n",
        "\"*** YOUR CODE HERE ***\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xn2luqwLbPA"
      },
      "source": [
        "**4c)** Check with a couple of random examples that the encoding was done correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byF5cysXdmcD"
      },
      "outputs": [],
      "source": [
        "# encoding check\n",
        "\n",
        "\"*** YOUR CODE HERE ***\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyz4wNAXv06U"
      },
      "source": [
        "---\n",
        "\n",
        "## Part B: Machine Learning\n",
        "\n",
        "We are now ready to apply a machine learning approach to our data: a neural network should learn to recognize the toxicity of a molecule by looking at its SMILE sequence.\n",
        "\n",
        "We first shuffle the dataset to avoid ordering bias and split it in a train and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8x87eH-usYD"
      },
      "outputs": [],
      "source": [
        "# we shuffle the dataset\n",
        "X, Y = sklearn.utils.shuffle(smiles_enc, toxicity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaqHCIFvUQ4"
      },
      "outputs": [],
      "source": [
        "# we split the dataset in a train and a validation set\n",
        "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(smiles_enc, toxicity, test_size=0.33, random_state=35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLTlnb8OGcHS"
      },
      "outputs": [],
      "source": [
        "# Dataset class, take a look at exercise class 3\n",
        "class Data(torch.utils.data.Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index].float(), self.y_data[index].float()\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "# Define batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Training data\n",
        "train_data = Data(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Validation data\n",
        "val_data = Data(X_val, y_val)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTL2ZBXFbOsZ"
      },
      "source": [
        "---\n",
        "\n",
        "As an example, the following code defines the training and validation functions for a given neural network. You might recongnize the functions from previous exercise sheets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_BN2cILPeXH"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  \"\"\"This function iterates over the training set once and trains the network with batches of data\"\"\"\n",
        "  # collect correct classifications for accuracy computation\n",
        "  number_of_correctly_classified_samples = 0\n",
        "  total_number_of_samples = len(train_data)\n",
        "\n",
        "  # iterate over all batches of inputs and labels\n",
        "  for inputs, labels in train_loader:\n",
        "  \n",
        "    # forward the data trough the network\n",
        "    logits = simple_network(inputs).flatten()\n",
        "    # collect the correct results\n",
        "    number_of_correctly_classified_samples += sum((logits > 0.5) == labels)\n",
        "\n",
        "    # compute the loss between the network output and the labels\n",
        "    J = loss_func(logits, labels)\n",
        "\n",
        "    # compute the gradients of the loss w.r.t. the learnable parameters\n",
        "    J.backward()\n",
        "    # perform a weight update step\n",
        "    optimizer.step()\n",
        "\n",
        "    # clear the gradients to start freshly next round\n",
        "    # DO NOT REMOVE!\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return number_of_correctly_classified_samples / total_number_of_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHOSZG5tPxb-"
      },
      "outputs": [],
      "source": [
        "def validation_accuracy():\n",
        "  number_of_correctly_classified_samples = 0\n",
        "  total_number_of_samples = len(val_data)\n",
        "\n",
        "  # iterate over all batches in the validation set\n",
        "  for inputs, labels in val_loader:\n",
        "    # forward the inputs through the network\n",
        "    logits = simple_network(inputs).flatten()\n",
        "    # compute how many samples in the batch were correctly classified\n",
        "    number_of_correctly_classified_samples += sum((logits > 0.5) == labels)\n",
        "    \n",
        "  \n",
        "  # return the accuracy\n",
        "  return number_of_correctly_classified_samples / total_number_of_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEz_niIyBBHW"
      },
      "source": [
        "---\n",
        "\n",
        "**5a)** Now define a neural network having two dense layers with 10 units, ReLU activation functions and dropout layers. Then select a suitable loss function for this binary classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOrdovd9NviU"
      },
      "outputs": [],
      "source": [
        "simple_network = torch.nn.Sequential(\n",
        "  # We first flatten the two dimensional input \n",
        "  torch.nn.Flatten(),\n",
        "  # first layer (input dim = length_of_longest_seq * number_of_unique_chars, hidden units)\n",
        "\n",
        "  \"*** YOUR CODE HERE ***\"\n",
        " \n",
        "  # activation function\n",
        "  \n",
        "  \"*** YOUR CODE HERE ***\"\n",
        "\n",
        "  # dropout layer to fight overfitting\n",
        "\n",
        "  \"*** YOUR CODE HERE ***\"\n",
        "\n",
        "  # second layer\n",
        "  \n",
        "  \"*** YOUR CODE HERE ***\"\n",
        "\n",
        "  # activation function\n",
        "  \n",
        "  \"*** YOUR CODE HERE ***\"\n",
        "\n",
        "  # dropout layer to fight overfitting\n",
        "\n",
        "  \"*** YOUR CODE HERE ***\" \n",
        "\n",
        "  # output layer (hidden units, output dim)\n",
        "\n",
        "  \"*** YOUR CODE HERE ***\"\n",
        "\n",
        "  torch.nn.Sigmoid() \n",
        ")\n",
        "\n",
        "# extract the parameters that we want to optimize\n",
        "learnable_parameters = simple_network.parameters()\n",
        "\n",
        "# select an optimizer and pass on these learnable parameters\n",
        "optimizer = torch.optim.Adam(learnable_parameters)\n",
        "\n",
        "# select an appropriate loss function\n",
        "loss_func = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8btWqECfPuLr",
        "outputId": "3f4a9c67-92c9-48c4-9d74-34fb4080a859"
      },
      "outputs": [],
      "source": [
        "# lists to store the training and validation accuracies\n",
        "train_accs = []\n",
        "validation_accs = []\n",
        "\n",
        "# Number of epochs\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # train the network\n",
        "  train_acc = train()\n",
        "  train_accs.append(train_acc)\n",
        "\n",
        "  # disable gradient computation during validation\n",
        "  with torch.no_grad():\n",
        "    # compute validation accuracy\n",
        "    val_acc = validation_accuracy()\n",
        "    validation_accs.append(val_acc)\n",
        "  # report it\n",
        "  print(f\"Epoch {epoch+1}: training accuracy {train_acc:1.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVMdLYtQ_-ai"
      },
      "source": [
        "The optimisation history can be visualized by plotting the accuracy of the train and of the validation set as function of the epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2P4UevCK2U"
      },
      "source": [
        "**5b)** Plot the accuracy on training and validation set for each epoch of this neural network. What can be said about the results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU4MWjOSAdBN"
      },
      "outputs": [],
      "source": [
        "# Plot of the optimisation history\n",
        "\n",
        "\"*** YOUR CODE HERE ***\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd7XpbpqkjWC"
      },
      "source": [
        "Q: What can be said about these results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ-yuEZKkq_q"
      },
      "source": [
        "A: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5lgIFnXwswy"
      },
      "source": [
        "---\n",
        "\n",
        "In a lot of applications the optimization of the accuracy might be the wrong goal. For example, predicting a non-toxic molecule as toxic is not equally worse than predicting a toxic one as non-toxic. Therefore, we have to consider alternative metrics:\n",
        "\n",
        "**6a)** Define and explain the following metrics\n",
        "\n",
        "* Sensitivity / True Positive Rate (TPR) \n",
        "\n",
        "A:\n",
        "\n",
        "\n",
        "* False Negative Rate (FNR)\n",
        "\n",
        "A:\n",
        "\n",
        "* Specificity / True Negative Rate (TNR)\n",
        "\n",
        "A:\n",
        "\n",
        "* False Positive Rate (FPR)\n",
        "\n",
        "A:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYsl7_rxpd_M"
      },
      "source": [
        "---\n",
        "\n",
        "We first calculate the metrics for predictions on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0cUu4fqPVF7"
      },
      "source": [
        "**6b)** Use the output of probabilities y_pred_logits to predict the toxicity of the sequences (0/1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp5RW3-NPPxX"
      },
      "outputs": [],
      "source": [
        "# we calculate metrics for predictions on validation set\n",
        "y_pred_logits = simple_network(X_val).flatten().detach()\n",
        "\n",
        "\n",
        "y_pred = ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTAS4kvoPwRC"
      },
      "source": [
        "**6c)** Calculate the metrics specified below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD5ck-5by-WW"
      },
      "outputs": [],
      "source": [
        "# Calculate confusion matrix\n",
        "CM = sklearn.metrics.confusion_matrix(y_pred,y_val)\n",
        "\n",
        "TN = CM[0][0]\n",
        "FN = CM[1][0]\n",
        "TP = CM[1][1]\n",
        "FP = CM[0][1]\n",
        "\n",
        "# Sensitivity or true positive rate\n",
        "TPR = ...\n",
        "# Specificity or true negative rate\n",
        "TNR = ...\n",
        "# Precision or positive predictive value\n",
        "PPV = ...\n",
        "# Negative predictive value\n",
        "NPV = ...\n",
        "# Fall out or false positive rate\n",
        "FPR = ...\n",
        "# False negative rate\n",
        "FNR = ...\n",
        "# False discovery rate\n",
        "FDR = ...\n",
        "\n",
        "# Overall accuracy\n",
        "ACC = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8chr1FRGHH7j"
      },
      "source": [
        "**6d)** Interpret your results. Does this support your findings from above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyRoXSIZQnqu"
      },
      "source": [
        "**How can we combine these quantities best?**\n",
        "\n",
        "The Receiver Operator Characteristic (ROC) curve is an evaluation metric for binary classification problems. It is a probability curve that plots the TPR against FPR at various threshold values and essentially separates the \"signal\" from the \"noise\". The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve.\n",
        "\n",
        "The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes. A random oracle has AUC = 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjG2M3VFPE_4"
      },
      "source": [
        "**7a)** Use the sklearn functions `sklearn.metrics.roc_curve` and `sklearn.metrics.roc_auc_score` to plot the ROC curve and the area underneath it. Note that you should use `y_pred_logits` as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9d-KZc7JORX"
      },
      "outputs": [],
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "\n",
        "fpr, tpr, thresholds = ...\n",
        "roc_auc = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27LRPG63H59g"
      },
      "outputs": [],
      "source": [
        "plt.plot(\n",
        "    fpr,\n",
        "    tpr,\n",
        "    color=\"darkorange\",\n",
        "    label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
        ")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver operator characteristic curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGWQPmVYMq51"
      },
      "source": [
        "**7b)** Interpret your results. What is an advantage of the AUC score? What could be a disadvantage?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.6.15 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
