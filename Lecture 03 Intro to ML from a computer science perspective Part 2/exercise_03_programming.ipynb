{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Machine Learning -- An Interdisciplinary Introduction\n",
    "\n",
    "## Convolutional Networks and Adversarial Examples\n",
    "\n",
    "\n",
    "We use the deep learning framework PyTorch (http://pytorch.org) to implement an image classification system where images of handwritten digits shall be classified.\n",
    "\n",
    "Before we start, we should assure that we have activated CUDA -- otherwise training might take very long.\n",
    "In Google Colaboratory:\n",
    "\n",
    "1. Check the options Runtime -> Change Runtime Type on top of the page.\n",
    "2. In the popup window, select hardware accelerator GPU.\n",
    "\n",
    "Afterward, the following command should run successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "  print(\"Successfully enabled CUDA processing\")\n",
    "else:\n",
    "  print(\"CUDA processing not available. Things will be slow :-(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Discuss issues in Postal Code Recognition\n",
    "\n",
    "\n",
    "One application of handwritten digit classification is the automatic sorting of letters by postal code.\n",
    "Given a photograph of a letter, discuss the steps that are necessary in order to perform the classification task.\n",
    "What kinds of issues might arise, and how would the machine learning system typically handle these?\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The images that we will use are already pre-cropped and provided by a dataset in PyTorch.\n",
    "The dataset comes with labeled data, so each of the images is accompanied by an according label (the associated digit class).\n",
    "Using the provided `transform`, the images are stored as `torch.tensor`s in the format of $C\\times H\\times W$, where $C$ is the number of color channels (for our images we have only one channel) and $H$ and $W$ are the height and width of the image in pixels.\n",
    "Let us have a look into some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot\n",
    "pyplot.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# load the dataset\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "  # set automatic downloading of data\n",
    "  download = True,\n",
    "  # here, we will use the training set\n",
    "  train = True,\n",
    "  # we need to provide a local directory where to download the data to\n",
    "  root = \"./MNIST\",\n",
    "  # we need to convert the images to something that pytorch understands\n",
    "  transform = torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# we plot 100 example of images, and we print their respective labels\n",
    "pyplot.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "  for j in range(10):\n",
    "    # create a subplot for each of the samples\n",
    "    pyplot.subplot(10, 10, i*10+j+1)\n",
    "    # get the image and the label from the dataset\n",
    "    image, label = dataset[i*10+j] \n",
    "    # show the image after removing the channel and tranforming it to something, matplotlib understands\n",
    "    pyplot.imshow(image[0].numpy())\n",
    "    # remove axiis labels to make the plot more beautiful\n",
    "    pyplot.axis(\"off\")\n",
    "    # write the labels to console, using the same grid format\n",
    "    print(label, end=\", \")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network\n",
    "\n",
    "In order to work on images, we will make use of a convolutional network with two layers of convolutions (`torch.nn.Conv2d`) and one fully-connected (`torch.nn.Linear`) layer to perform the classification.\n",
    "The first two layers are followed by a non-linearity so that the output of the network can form non-linear combinations of input pixels.\n",
    "Finally, the fully-connected layer needs to output 10 values, one for each digit class.\n",
    "\n",
    "Convolutional layers in `PyTorch` have several parameters, including:\n",
    "\n",
    "* `kernel_size`: The size of the kernel, can be specified as a single `int` or a tuple of two `int`'s.\n",
    "* `out_channels`: The number of produced channels, which we need to specify. This is also the number of kernels that we want to be learned in this layer.\n",
    "* `in_channels`: The number of incoming channels, which should be `1` for the first layer, or the number of output channels of the previous convolutional layer.\n",
    "* `padding`: How many pixels should be padded on both sides of the image / feature map?\n",
    "* `stride`: How many pixels should we step for applying our kernels.\n",
    "\n",
    "Also, fully-connected layers have a few parameters:\n",
    "\n",
    "* `out_features`: The selected dimension that is produced by this layer.\n",
    "* `in_features`: The dimension of the incoming data.\n",
    "\n",
    "Different activation functions exist, including `torch.nn.ReLU`, `torch.nn.Sigmoid` and `torch.nn.Tanh`.\n",
    "\n",
    "## Task 2: Network implementation\n",
    "\n",
    "First, we need to select an appropriate set of parameters of the layers.\n",
    "Decide, how large the kernels are, how many input and output channels we need in each convolution, if and how you do down-scaling of the convolution results, and which non-linearity should be applied.\n",
    "Determine the number of parameters that are output from the last convolution layer and input to the fully-connected layer -- how can you compute the number without computing it?\n",
    "\n",
    "For the implementation of our network, you can rely on the `torch.nn.Sequential` model that connects the layers in the given order.\n",
    "Remember that the last fully-connected layer needs to have 10 outputs, one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_network = torch.nn.Sequential(\n",
    "  # first convolutional layer\n",
    "  torch.nn.Conv2d(in_channels = 1, ...),\n",
    "\n",
    "  # activation function\n",
    "  ...\n",
    "\n",
    "  # more convolutional layers?\n",
    "  ...\n",
    "\n",
    "  # converting the channeled structure into one-dimensional data\n",
    "  torch.nn.Flatten(),\n",
    "\n",
    "  # Apply fully-connected layer(s)\n",
    "  torch.nn.Linear(...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "\n",
    "\n",
    "In order to train our convolutional network on our training data, we need to define how large the error is that our current network is making.\n",
    "For example, when we present the network with a sample of class 4, and the network predicts a 9 with 95% confidence, the error should be high.\n",
    "When showing a sample of class 3 and the network predicts a 3 with 60% confidence, the error is not that high.\n",
    "\n",
    "There are several choices of loss functions, such as the mean squared error `torch.nn.MSE`, the binary cross-entropy (BCE) loss `torch.nn.BCELoss`, the negative log-likelihood (NLL) loss `torch.nn.NLLLoss` a.k.a. the categorical cross-entropy (CCE) loss, as well as combinations of activation and loss functions such as logistic activation and BCE loss `torch.nn.BCEWithLogitsLoss`, or SoftMax activation with NLL loss `torch.nn.CrossEntropyLoss`.\n",
    "\n",
    "## Task 3: Loss Function\n",
    "\n",
    "Select the loss function that best fits to your network implementation and the desired task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an appropriate loss function\n",
    "loss = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the second component of our training, we need to decide which learning strategy we want to apply.\n",
    "Several such strategies are implemented in PyTorch, such as stochastic gradient descent (SGD) `torch.optim.SGD`, RMSProp `torch.optim.RMSProp`, or adaptive moments (Adam) `torch.optim.Adam`.\n",
    "All of these require a set of learnable parameters that shall be optimized -- the weight of our network layers -- as well as a carefully selected learning rate `lr`.\n",
    "Some optimizers have further parameters, which can be obtained through the documentation.\n",
    "\n",
    "## Task 4: Optimizer\n",
    "\n",
    "Select an optimizer and a learning rate.\n",
    "What would be a good strategy to select an appropriate learning rate?\n",
    "How can we tell if one optimizer is better than the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the parameters that we want to optimize\n",
    "learnable_parameters = convolutional_network.parameters()\n",
    "\n",
    "# select an optimizer and pass on these learnable parameters\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Data Processing\n",
    "\n",
    "To speed up processing, we will be working with batches of samples.\n",
    "PyTorch provides a simple interface for creating batches, a so-called data loader.\n",
    "The data loader takes a dataset (such as our MNIST dataset) and a desired batch size, and will provide us with batches of images and labels.\n",
    "How large the batch size should be is an open debate, usually people use batches as large as fits their GPU memory -- typically restricted to powers of 2: `32, 64, 128, 256, ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further speed up processing, we will run on the GPU.\n",
    "For this, we can select the specific device `\"cuda\"`, onto which all of the parameters and the data will be ported.\n",
    "We here start with porting the parameters of the network, later we need to remember to also port all inputs and labels onto the device.\n",
    "\n",
    "There are several ways to port samples to devices. Choose one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "convolutional_network = convolutional_network.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training\n",
    "\n",
    "For training the network on the training data, we iterate over the batches of our dataset and perform a weight update step for each batch.\n",
    "For this purpose, we first need to pass our input through the network in order to obtain the output of the network, which is the logits that will be fed into the SoftMax function to obtain one probability value for each class for each sample.\n",
    "These logits will be passed to our loss function that will estimate how well the output of the network fits to our labels.\n",
    "From this loss value (which is a `torch.tensor` with a single element), we can compute the gradient of the loss with respect to all learnable parameters of the network.\n",
    "In PyTorch, this is done using the `tensor.backward()` function.\n",
    "Finally, the optimizer will perform the update step, i.e., modify the learnable parameters such that the loss value gets minimized.\n",
    "\n",
    "## Task 5: Training\n",
    "\n",
    "Write a function that takes the loss function, the optimizer and the data loader to train on all of the samples once. \n",
    "Do not forget to put all the input and labels to the same device as the network's parameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  \"\"\"This function iterates over the training set once and trains the network with batches of data\"\"\"\n",
    "  # iterate over all batches of inputs and labels\n",
    "  for inputs, labels in data_loader:\n",
    "    # put the data onto the same device as the model\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # forward the data trough the network\n",
    "    logits = ...\n",
    "\n",
    "    # compute the loss between the network output and the labels\n",
    "    J = loss(...)\n",
    "\n",
    "    # compute the gradients of the loss w.r.t. the learnable parameters\n",
    "    J.backward()\n",
    "    # perform a weight update step\n",
    "    optimizer.step()\n",
    "\n",
    "    # clear the gradients to start freshly next round\n",
    "    # DO NOT REMOVE!\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Validation\n",
    "\n",
    "In order to assess the quality of the training and to detect overfitting, people regularly evaluate their network's behavior on unseen data.\n",
    "They define a validation set of annotated samples, for which they compute some metrics, such as the validation loss (using the loss function from above) or by assessing the classification accuracy.\n",
    "For this validation set, we will use the same structure, i.e., batches of samples from a dataset.\n",
    "For MNIST, we make use of the test set for our validation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the validation set\n",
    "validation_set = torchvision.datasets.MNIST(root=\"MNIST\", train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing the accuracy of the network on validation set, we need to have an implementation that takes batches of network outputs (logits).\n",
    "We count, how often the maximum output of a sample is identical to the class index, and we return this number and the total number of samples in the given batch.\n",
    "Remember that the logits are in dimension $B\\times O$, where $B$ is the size of the batch and $O=10$ is the number of classes, while the targets is of size $B$ and contains the class index of the correct class for each sample in the batch.\n",
    "We compute the number of correctly classified samples of the whole validation set and divide this number by the number of validation samples to get the accuracy value.\n",
    "\n",
    "## Task 6: Validation Accuracy\n",
    "\n",
    "Implement a function that iterates over the validation set and computes the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_classes(logits):\n",
    "  # For each sample, we compute the index that corresponds to the maximum value\n",
    "  return ...\n",
    "\n",
    "def validation_accuracy():\n",
    "  number_of_correctly_classified_samples = 0\n",
    "  total_number_of_samples = ...\n",
    "\n",
    "  # iterate over all batches in the validation set\n",
    "  for inputs, labels in validation_loader:\n",
    "    # put the data onto the same device as the model\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # forward teh inputs through the network\n",
    "    logits = ...\n",
    "    # compute how many samples in the batch were correctly classified\n",
    "    number_of_correctly_classified_samples += ...\n",
    "    \n",
    "  # return the accuracy\n",
    "  return number_of_correctly_classified_samples / total_number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Finally, we can implement our training loop, where we train the network for several epochs.\n",
    "In each epoch, we first train the network on the training data (using our `train` function), and then we calculate and report the validation set accuracy.\n",
    "During validation, since there is no need to calculate gradients, we will disable the gradient computation temporarily.\n",
    "\n",
    "Note: for well-chosen parameters, the validation accuracy should be above 90% after the first epoch already.\n",
    "Running this cell might require several minutes, depending on your chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "  # train the network\n",
    "  train()\n",
    "  # disable gradient computation during validation\n",
    "  with torch.no_grad():\n",
    "    # compute validation accuracy\n",
    "    acc = validation_accuracy()\n",
    "  # report it\n",
    "  print(f\"Epoch {epoch+1}: accuracy {acc:1.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of our Network\n",
    "\n",
    "\n",
    "Now, we can see how well the separate classes have been trained.\n",
    "For this purpose, we compute the confusion matrix between the predicted classes of the validation set samples and their labels.\n",
    "\n",
    "Since the majority of samples are correctly classified, we might ignore these cases in our confusion matrix since otherwise the other samples are barely visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros((10,10))\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in validation_loader:\n",
    "    # get output of network\n",
    "    logits = convolutional_network(inputs.to(device))\n",
    "    # get the predicted classes from the logits\n",
    "    predicted = predicted_classes(logits)\n",
    "    # calculate confusion\n",
    "    confusion_matrix[labels, predicted] += 1\n",
    "\n",
    "# reset the diagonal to 0\n",
    "confusion_matrix[torch.eye(10).bool()] = 0\n",
    "\n",
    "# plot confusion matrix\n",
    "pyplot.figure(figsize=(6,5))\n",
    "pyplot.imshow(confusion_matrix, cmap=\"jet\")\n",
    "# make plot more beautiful\n",
    "pyplot.xticks(range(10))\n",
    "pyplot.yticks(range(10))\n",
    "pyplot.xlabel(\"Predicted Class\")\n",
    "pyplot.ylabel(\"Class Label\")\n",
    "pyplot.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have gotten an overview of the errors of the network, let us have a look into the examples that are misclassified.\n",
    "\n",
    "## Task 7: Collect Wrongly-Classified Samples\n",
    "\n",
    "Go through the validation set again and collect all the incorrectly classified samples.\n",
    "For each wrongly-predicted sample, remember its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collect all wrongly-classified samples based on their predicted class\n",
    "wrong_samples = [[] for o in range(10)] \n",
    "\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in validation_loader:\n",
    "    # put the data onto the same device as the model\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # get output of network\n",
    "    logits = ...\n",
    "    # get the predicted classes from the logits\n",
    "    predicted = ...\n",
    "\n",
    "    # get the indexes where labels and predicted class mismatch\n",
    "    indexes = ...\n",
    "\n",
    "    inputs = inputs.to(\"cpu\")\n",
    "    for i in indexes:\n",
    "      # Store all samples that have been predicted wrongly using the predicted class \n",
    "      wrong_samples[predicted[i]].append(inputs[i,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the wrong samples together in one plot such that you can identify their predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot all images that are wrongly predicted\n",
    "# first, compute the width of the plot\n",
    "max_size = max(len(v) for v in wrong_samples)\n",
    "\n",
    "# create a plot with suddifient space\n",
    "pyplot.figure(figsize=(max_size, 10))\n",
    "# iterate over all predicted classes\n",
    "for i, samples in enumerate(wrong_samples):\n",
    "  # iterate over the images that have been wrongly predicted as this class\n",
    "  for j, image in enumerate(samples):\n",
    "    # plot the image\n",
    "    pyplot.subplot(10, max_size, i * max_size + j+1)\n",
    "    pyplot.imshow(image)\n",
    "    pyplot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Evaluate Wrong Predictions\n",
    "\n",
    "Go through the list of wrongly predicted samples. \n",
    "Did the network make mistakes that you can understand?\n",
    "Discuss some examples where humans could have made the same mistake, and some examples where the mistake seems unreasonable to humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Samples\n",
    "\n",
    "\n",
    "While the network was able to learn to classify digits very well, the question is if it used features that humans would have used, too.\n",
    "Hence, the question arises: can we modify the images such that we as humans would still see the original label, but we can get the network to classify something else?\n",
    "Let us try.\n",
    "\n",
    "First, we need to collect some test samples that are classified correctly by the network.\n",
    "About 10 for each class should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_samples = [[] for o in range(10)] \n",
    "\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in validation_loader:\n",
    "    # put the data onto the same device as the model\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # get output of network\n",
    "    logits = convolutional_network(inputs)\n",
    "    # get the predicted classes from the logits\n",
    "    predicted = predicted_classes(logits)\n",
    "\n",
    "    # get the indexes where labels and predicted class match\n",
    "    indexes = torch.where(predicted == labels)[0]\n",
    "    for i in indexes:\n",
    "      correct_samples[predicted[i]].append(inputs[i])\n",
    "      \n",
    "# limit to 10 samples per class\n",
    "correct_samples = [torch.stack(s[:10]) for s in correct_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we implement a simple method where we use the gradient of the loss w.r.t. the pixels of the image in order to modify the image such that the loss is maximized.\n",
    "PyTorch allows us to do that very simply, but just requesting the gradients for the input images.\n",
    "\n",
    "We will have a look into two different ways of modifying the input using the gradient of our loss $\\mathcal J$: \n",
    "\n",
    "$\\tilde x = x + \\alpha \\cdot F(\\nabla_x \\mathcal J)$\n",
    "\n",
    "The first method, called the Fast Gradient Sign (FGS) will produce: \n",
    "\n",
    "$F_{\\mathrm{FGS}}(\\nabla_x) = \\mathrm{sign}(\\nabla_x)$, \n",
    "\n",
    "whereas the second version, the Fast Gradient Value (FGV) uses a version of the gradient scaled by its maximum absolute value.\n",
    "\n",
    "$F_{\\mathrm{FGV}}(\\nabla_x) = \\frac{\\nabla_x}{\\max |\\nabla_x|}$.\n",
    "\n",
    "Iterate through the correctly classified samples.\n",
    "Assure that the gradient is requested for the inputs.\n",
    "Forward the inputs through the network.\n",
    "Compute the loss w.r.t. the original labels and compute the gradients.\n",
    "Generate adversarial samples by applying FGS or FGV; the gradient should now be stored in `inputs.grad`.\n",
    "Forward the adversarial samples through the network again and see what classes are now classified.\n",
    "Write these classes to console, and plot the adversarial samples in a grid.\n",
    "Select a value for $0<\\alpha\\leq1$ that produces little perturbations but changes the network output of most of the samples.\n",
    "Generate FGS and FGV adversarial samples and look at their differences in terms of introduced patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(10,10))\n",
    "\n",
    "for label, inputs in enumerate(correct_samples):\n",
    "  inputs.requires_grad_(True)\n",
    "  logits = convolutional_network(inputs.to(device))\n",
    "  J = loss(logits, torch.tensor([label]*len(inputs), device=device))\n",
    "  J.backward()\n",
    "\n",
    "  grad = inputs.grad.detach()\n",
    "#  amax = torch.amax(torch.abs(grad), dim=(1,2,3), keepdim=True)\n",
    "#  adversarial = inputs + 0.2 * grad / amax\n",
    "  adversarial = inputs + 0.1 * torch.sign(grad)\n",
    "\n",
    "  # predict the classes for the adversarial samples\n",
    "  logits = convolutional_network(adversarial.to(device))\n",
    "  predicted = predicted_classes(logits)\n",
    "  print(label, predicted.tolist())\n",
    "\n",
    "  # plot the resulting images\n",
    "  for i in range(10):\n",
    "    ax = pyplot.subplot(10, 10, label*10+i+1)\n",
    "    ax.imshow(adversarial[i,0].detach().cpu())\n",
    "    pyplot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Adversarial Threat\n",
    "\n",
    "Given that deep networks can be fooled this easily, discuss the consequences for using deep-learning based methods in several applications.\n",
    "Envision at least one application that is not strongly influenced by this fact, and one that should not make use of deep learning-based systems before this issue is not solved."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a29cabff5744fce69e08a959ab87b9e77a9f67b498d08783caa8c3bb16f23a00"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
