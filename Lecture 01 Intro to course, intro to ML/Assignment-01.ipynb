{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Machine Learning -- An Interdisciplinary Introduction\n",
    "\n",
    "In our exercises, we will introduce and utilize several machine learning techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### Simple Data Structures\n",
    "This first JuPyter notebook explains the basics of machine learning, which is a Multi-Dimensional Array structure.\n",
    "Many of you are surely familiar with scalar value. \n",
    "These are just single numbers that have a specific value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Operations\n",
    "All mathematical operations can be applied to matrices, and we can use the default python operators `+, -, *, /, //, %, **`.\n",
    "You can also modify matrices inplace using `+=, -=, /=, //=, %=, **=`.\n",
    "By default, all operations are just done element-wise.\n",
    "This is only possible when the dimensionality of the operands are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, different data structures are used regularly.\n",
    "One of these structures is a list, which can contain various different Python objects.\n",
    "Note that in python, everything is an object, even imported modules are objects that can be put into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "values = [0, 1., 1e-4, True, \"Wednesday\", None, math]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we typically rely on numerical data only; how other types of data are handled will be discussed later in this lecture series.\n",
    "Any list of numerical values can be represented as a mathematical vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = [0.,1.,2.,3.,4.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since a list can contain any type of objects, lists can also contain lists, in which case we talk about nested lists.\n",
    "We define a nested list of lists with different length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested = [\n",
    "  [0.,1.,2.,3.,4.],\n",
    "  [6.,7.,8.,9.],\n",
    "  [11.,12.,13.]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all of the nested lists have the same number of element (the same dimensionality), they build the mathematical concept of a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [\n",
    "  [0.,1.,2.,3.,4.],\n",
    "  [6.,7.,8.,9.,10.],\n",
    "  [11.,12.,13.,14.,15.]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the matrix has three rows and five columns.\n",
    "Similarly, we can extend this idea to build a tensor, which is basically adding another layer of nesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = [\n",
    "  [[0.,1.], [2.,3.], [4.,5.], [6.,7.]],\n",
    "  [[8.,9.], [10.,11.], [12.,13.], [14.,15.]],\n",
    "  [[16.,17.], [18.,19.], [20.,21.], [22.,23.]]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tensor has the dimensionality of $3\\times4\\times2$.\n",
    "Factually, also the scalars, vectors and matrices are specializations of tensors with zero, one or two levels.\n",
    "Furthermore, tensors are not limited to three levels, but larger structures are also possible -- for example, deep learning systems usually use four or five level tensors.\n",
    "\n",
    "## Task 1\n",
    "\n",
    "Obtain the dimensionality of the above data structures.\n",
    "The length of a list can be obtained using the `len` function in python.\n",
    "To index an element in python, you can use the index operators, e.g., `values[1]`.\n",
    "For the vector, the matrix and the tensor, obtain the dimensionality of these data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the length of the vector\n",
    "print(...)\n",
    "\n",
    "# print the dimensionality of the matrix\n",
    "print(..., ...)\n",
    "\n",
    "# print the dimensionality of the tensor\n",
    "print(..., ..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Numpy Arrays\n",
    "While it is possible to work with these types of nested lists, it is often easier and faster to work with a dedicated data structure for numerical data.\n",
    "Such a data structure is provided in the `torch` python library.\n",
    "The basic data structure represents any multidimensional mathematical tensor, therefore the data structure is called `torch.tensor`.\n",
    "A `torch.tensor` is a Python class and can be constructed in various different ways.\n",
    "\n",
    "The easiest way of defining `torch.tensor`s is to construct them from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "my_data = torch.tensor([\n",
    "  [-1., 2., 3],\n",
    "  [3., -4., 1e-4]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the contents of the array using pythons built-in `print` function.\n",
    "We can also obtain the dimensionality of the data by asking for its `shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_data)\n",
    "print(my_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create `torch.tensor`s for all our data structures from above.\n",
    "Print the shapes of all structures.\n",
    "What happens to our nested list above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn all of our data structures into torch tensors\n",
    "torch_scalar = ...\n",
    "torch_vector = ...\n",
    "torch_matrix = ...\n",
    "torch_tensor = ...\n",
    "\n",
    "# print their shapes\n",
    "...\n",
    "\n",
    "# what about nested arrays of different lengths?\n",
    "torch_nested = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of defining `torch.tensor`s is by defining their `shape`.\n",
    "The function to create an empty array is the `torch.empty` function.\n",
    "A specific data type can be specified using the `dtype` argument, which can take various types, such as `float` (the default), `int`, `bool`, `complex` and alike.\n",
    "The data is usually **uninitialized** and contain anything that resides in that region of the RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_tensor = torch.empty((4,7), dtype=torch.float32)\n",
    "print(empty_tensor)\n",
    "\n",
    "int_tensor = torch.empty((2,3), dtype=torch.uint8)\n",
    "print(int_tensor)\n",
    "\n",
    "bool_tensor = torch.empty((2,3), dtype=torch.bool)\n",
    "print(bool_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to initialize the data, you can use various functions.\n",
    "For examples, you can initialize with `0`, or `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_matrix = torch.zeros((3,4))\n",
    "print(zero_matrix)\n",
    "\n",
    "one_matrix = torch.ones((2,4,3), dtype=torch.int)\n",
    "print(one_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to create random data using functionality from `torch`.\n",
    "Random values between 0 and 1 are obtained using `torch.rand`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.rand((2,4))\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal distributed values can be obtained with `torch.normal` where one can specify the mean and the standard deviation of the values.\n",
    "For example, if you want to have 6 two-dimensional normal distributed vectors with `mean` $(-3,1)$ and standard deviation `std` of $(2,1)$, you can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_tensor = torch.normal(mean = torch.tensor([(-3,1.)]*6), std = torch.tensor([(2.,1.)]*6))\n",
    "print(normal_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More random distributions can be found in the `torch.distributions` package, for more information check the following [link](https://pytorch.org/docs/stable/distributions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_tensor = torch.distributions.normal.Normal(loc=torch.tensor((-3.,1.)), scale=torch.tensor((2.,1.))).sample([6])\n",
    "print(normal_tensor)\n",
    "\n",
    "bernoulli_tensor = torch.distributions.bernoulli.Bernoulli(probs=0.5).sample([4,3])\n",
    "print(bernoulli_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can also be combined using `torch` functionality.\n",
    "For example, `torch.concat` will concatenate two tensors (where the all but the first level must be identically shaped), while `torch.stack` will produce a new dimension (all dimensions must be identically shaped):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = torch.concat((torch.zeros((2,4)), torch.ones((3,4))))\n",
    "print(concatenated)\n",
    "\n",
    "stacked = torch.stack((torch.zeros((2,4)), torch.ones((2,4))))\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "All mathematical operations can be applied to tensors, and we can use the default python operators `+, -, *, /, //, %, **`.\n",
    "You can also modify tensors inplace using `+=, -=, /=, //=, %=, **=`.\n",
    "By default, all operations are just done element-wise.\n",
    "This is possible when the dimensionality of the operands are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = torch.zeros((3,2)) - torch.ones((3,2))\n",
    "print(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical operations can also be **broadcasted**, i.e., dimensionalities are automatically adapted.\n",
    "The most simple broadcasting is via a scalar, but more complicated broadcasts can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_range = torch.rand((4,2)) * 10. - 5.\n",
    "print(random_range)\n",
    "\n",
    "mixes = torch.ones((3,2)) * torch.tensor([-1,3])\n",
    "print(mixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of tensors can be done using the default comparison operators `>, >=, <, <=, ==`.\n",
    "These operations are applied element-wise and result in boolean tensors.\n",
    "If you want to reduce these to a single value (to be used in an `if` condition), you can use the `all` or `any` functions.\n",
    "Broadcasting applies for comparison operators as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_positives = random_range > 0\n",
    "print(random_positives)\n",
    "print(random_positives.all())\n",
    "print(random_positives.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, other mathematical operations are applied element-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.,2.,3.,4.,5.])\n",
    "print(torch.exp(x))\n",
    "print(torch.sin(x))\n",
    "print(torch.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Arrays\n",
    "Arrays can be indexed in several ways, typically using the index `[]` operator.\n",
    "To obtain a certain value, you can specify the exact index.\n",
    "Indexing starts at 0 and negative indexes work similarly as with python lists.\n",
    "Other than for python lists, indexes can contain tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal_tensor[3][1])\n",
    "print(normal_tensor[3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, when using the index operator, a scalar value is returned, which is defined as a `torch.tensor` with a single value.\n",
    "If you want to obtain the raw data, you can use the `.item()` function on the tensor; note that this only works for scalars, not for vectors, matrices or higher-order tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal_tensor[3,1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use boolean arrays for indexing.\n",
    "Note that also integral arrays are allowed, but results might be different from what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_range[random_positives] *= -1\n",
    "print(random_range)\n",
    "print(torch.all(random_range <= 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When indexing arrays with fewer entries than levels, sub-arrays are returned.\n",
    "Indexing always starts at the first level, missing levels are assumed to be all elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch_matrix[0])\n",
    "print(torch_matrix[1])\n",
    "print(torch_tensor[0])\n",
    "print(torch_tensor[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `start:end` to define ranges, where `:` just represents all elements as this level. \n",
    "Similarly, you can define `start:end:step` to define slices.\n",
    "This can be useful, when you actually want to index the second level only.\n",
    "Note that negative `step`s are not allowed in PyTorch (in `numpy`, they are allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch_vector[1:3])\n",
    "print(torch_matrix[:,1])\n",
    "print(torch_tensor[-1,0:2:2,::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Generate a random array in dimension `(5,4)`, where the values are in range $[-2, 4]$.\n",
    "Multiply all negative values with 4, divide all positive values by 4.\n",
    "Print the array.\n",
    "Compute and print the sum of all elements in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random tensor in range [-2,4] with shape (5,4)\n",
    "random_array = ...\n",
    "# multiply negative values with 4\n",
    "...\n",
    "# divide positive values by 4\n",
    "...\n",
    "\n",
    "# print the tensor\n",
    "...\n",
    "\n",
    "# compute and print the sum of the elements in the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Tensors\n",
    "Several times, you will need to sort your tensors ascendingly.\n",
    "Similarly to the `sorted` function in python, you can sort an array using `torch.sort`.\n",
    "Note that this function returns two values: the sorted tensor, and the indexes that -- applied to the original unsorted tensor -- will provide the sorted tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted = torch.tensor([-4, 3, 7, -5, 0, 6, 4])\n",
    "sorted_array, sorted_indexes = torch.sort(unsorted)\n",
    "print(sorted_array)\n",
    "print(sorted_indexes)\n",
    "print(unsorted[sorted_indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Operations\n",
    "As mentioned above, by default all tensor operations are performed element-wise.\n",
    "Mathematical matrix operations can be applied using `torch` functionality.\n",
    "For example, the dot product between two tensors (matrices, vectors) can be performed via `torch.matmul`.\n",
    "Vector operations are, for example, `torch.inner`, `torch.outer`.\n",
    "Matrices can be transposed using `torch.transpose` or quickly the `.T` member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.rand((4))\n",
    "matrix = torch.rand((3,4))\n",
    "print(torch.matmul(matrix, vector))\n",
    "print(torch.matmul(vector, matrix.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reduce matrices by computing min, max, mean and standard deviation across a specific dimension `dim`.\n",
    "Please note that `torch.max` additionally returns the indexes across the given `dim` when a `dim` is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_array = torch.distributions.normal.Normal(torch.tensor((-3,4.)), torch.tensor((6.,7.))).sample([1000])\n",
    "print(torch.min(normal_array))\n",
    "print(torch.max(normal_array, dim=0))\n",
    "print(torch.mean(normal_array, dim=0))\n",
    "print(torch.std(normal_array, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly compute norms of vectors and matrices, or invert matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "print(torch.norm(vector).item())\n",
    "print(torch.inverse(torch.tensor([[2.,0.], [0.,-2.]])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since PyTorch is optimized for parallel processing, distance computations are not as straightforward.\n",
    " We first need to instantiate a distance object, and then we can compute distances: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean = torch.nn.PairwiseDistance(p=2)\n",
    "print(euclidean(vector, vector-2).item())\n",
    "\n",
    "cosine = torch.nn.CosineSimilarity(dim=0)\n",
    "print(cosine(vector, matrix[0]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with matplotlib\n",
    "\n",
    "Plotting is usually done with `matplotlib`, which typically handles `torch.tensor`s as expected.\n",
    "Here, we describe only standard functionality, much more can be done otherwise.\n",
    "All plots in the slides are generated with `matplotlib`.\n",
    "\n",
    "### Line plotting\n",
    "There are several ways of plotting a line in `matplotlib`.\n",
    "A straight line can be defined by a start and an end point.\n",
    "The `pyplot.plot` function will take all x-positions and y-positions in a list/array/tensor.\n",
    "How the line is plotted is defined using a `format` option, which combines color `rgbkmcy` and style `.+*xosd-:`.\n",
    "A blue line is plotted with format `b-`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "two_points = torch.tensor([\n",
    "  (-1,1),\n",
    "  (2,-2)\n",
    "])\n",
    "pyplot.plot(two_points[0], two_points[1], \"b-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, `matplotlib` plots points connected with straight lines. \n",
    "To be more fine-grained, use more offset positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0,6.001,2)\n",
    "pyplot.plot(x,torch.exp(x), \"r-\")\n",
    "\n",
    "x = torch.arange(0,6.001,0.01)\n",
    "pyplot.plot(x,torch.exp(x), \"g-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add labels, axis labels, and more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(torch.cos(x), \"g:\", label=\"cos\")\n",
    "pyplot.plot(torch.sin(x), \"r--\", label=\"sin\")\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"x\")\n",
    "pyplot.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Points\n",
    "Points can be plotted in various ways. \n",
    "For example, you can select a different marker instead of a line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 6.01, 0.5)\n",
    "pyplot.plot(x, x**2, \"gx\", label=\"$x^2$\")\n",
    "pyplot.plot(x, 2**x, \"mo\", label=\"$2^x$\")\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"x\")\n",
    "pyplot.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the points do not need to be related in any way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.rand(size=(100,2))\n",
    "pyplot.plot(points[:,0], points[:,1], \"rs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Create equidistant and sorted input values $-4\\leq x \\leq4$. (Hint: as shown prior you can do this with [torch.arange()](https://pytorch.org/docs/stable/generated/torch.arange.html))\n",
    "\n",
    "Compute the function $y = f(x)=2 x^2 + 10\\cos(x)$.\n",
    "\n",
    "Plot the function $(x,y)$ as a green line plot and label `function`. (Hint: look how prior plots where done with matplotlib)\n",
    "\n",
    "Add noise to your output $t = y + \\mathcal N(0,3)$.\n",
    "\n",
    "Plot the points $(x,t)$ as separate points with start shape and red color and label `points`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create equidistant input values x in range [-4, 4]\n",
    "x = ...\n",
    "# compute function y = 2x^2 + 10 cos(x)\n",
    "y = ...\n",
    "\n",
    "# plot function by providing points for x and y, with the label \"function\"\n",
    "...\n",
    "\n",
    "# select our targets t to be the function y with some additional Gaussian-distributed noise with mean 0 and std 3.\n",
    "t = y + ...\n",
    "\n",
    "# plot the points with a star marker with the label (\"points\")\n",
    "...\n",
    "\n",
    "# add the label using .legend() function\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
