{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9feada-59ca-498a-8ae8-9f8743645abd",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "The tf-idf (term frequency - inverse document frequency) is a measure of how important a specific word in a document $doc$ is to the document itself, within the context of a collection of documents $D$. \n",
    "\n",
    "It has been used in a variety of NLP-applications. In this task, you will calculate some tf-idf values for words in short texts by hand, in order to gain some intuition on how it works. \n",
    "\n",
    "The term frequency is calculated using the following formula: \n",
    "\n",
    "\n",
    "${\\sf tf}(w) = \\frac{C_w}{C_t}$\n",
    "\n",
    "where w is the word in question, $C_w$ is the total count of the word in the document and $C_t$ is the total word count of the document.\n",
    "\n",
    "Likewise, the inverse document frequency is calculated by this formula:\n",
    "\n",
    "${\\sf idf}(w)=\\log(\\frac{N}{|\\{doc \\in D:w \\in doc\\}|})$\n",
    "\n",
    "where $N$ is the total number of documents. The denominator here denotes the number of documents in the collection that contain the word $w$, and the whole fraction is then logarithmically scaled using the natural logarithm.\n",
    "\n",
    "To calculate the final tf-idf value, the two values simply need to be multiplied. This causes the tf to be scaled by the idf, so that words that appear in many or all documents are weighted less than words that appear in few documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938541b5-39ba-4cf4-ab5d-8f5561ba9775",
   "metadata": {},
   "source": [
    "You can find three short texts below. For each word in the texts, calculate the tf-idf value. Make sure to make each step of your calculation clear (if you repeat steps, you only need to write them down once). You may use a calculator or write some code to get to the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366db3e-5485-46c0-87e0-479026d887fa",
   "metadata": {},
   "source": [
    "### Text 1\n",
    "\n",
    "There are three trees growing in the garden. <br>\n",
    "The trees are very big. <br>\n",
    "They cast big shadows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291fddb-7b62-4b78-9794-56dc9f7fbb51",
   "metadata": {},
   "source": [
    "### Text 2\n",
    "\n",
    "Three kids play in the garden. <br>\n",
    "The shadows of the kids grow big in the evening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61809d20-c294-42d0-b5af-78999fcfa513",
   "metadata": {},
   "source": [
    "### Text 3\n",
    "The people are growing vegetables in the gardens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7b638-68a9-4d18-911c-36885ca2f4cb",
   "metadata": {},
   "source": [
    "[Your solution here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb9d82-a254-4bea-933e-52e22faebd86",
   "metadata": {},
   "source": [
    "### Questions\n",
    "Some of the words could have a tf-idf value of 0. Why is this the case? What does that mean conceptually?\n",
    "\n",
    "Did you spot any problems with this application of tf-idf? (Hint: Look at what kinds of linguistic properties are captured or ignored)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3358f-b9b2-4201-a05a-c48881b340fd",
   "metadata": {},
   "source": [
    "[Your answers here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf62148-d31c-4a5f-b6e9-9def57ba10cd",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "An application for the tf-idf values could be to determine the document which is most similar to a given document in a collection. This can be useful, for example, for automatic reading recommendations. <br>\n",
    "For this task, one could use a bag-of-words representation of a document. A bag-of words approach assumes that a document is characterised by the words it contains. <br>\n",
    "Thus, we are going to represent each text from Task 1 as a vector and compare them to each other using the cosine similarity:\n",
    "\n",
    "$\\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\|*\\|B\\|}$\n",
    "\n",
    "\n",
    "where $A$ and $B$ are vectors representing the texts to be compared. The higher $\\cos(\\theta)$ is, the smaller the angle between the verctors becomes, which can be interpreted as the two texts being more similar.\n",
    "\n",
    "The vector-representation for each text is a vector with dimension N, where N equals the number of words in the entire vocabulary containing all words that occur in any of the documents in the collection. Each cell of a text-vector corresponds to the tf-idf value of a word in the combined vocabulary with respect to the text the vector should represent.<br>\n",
    "Important: The entries in each vector have to correspond to the same words in all vectors, so, for example, if the first entry of the vector for text 1 contains the tf-idf value for the word \"the\", the first entry of all other text-vectors must also refer to \"the\". <br>\n",
    "\n",
    "Calculate the cosine similarity of text 1 and text 2, and text 1 and text 3. Determine which of the texts 2 and 3 is closer to text 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f4cb0-76d0-46f5-a6c8-9e1dab8b7af3",
   "metadata": {},
   "source": [
    "[Your solution here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb32a5-fe38-409d-ab79-df0a760d976b",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "In the lecture, you heard about word embeddings and the Word2Vec algorithm.\n",
    "\n",
    "1. In your own words, describe what word embeddings are.\n",
    "2. Briefly describe how Word2Vec works and what it is used for.\n",
    "3. What are the advantages of representing the words in a text as word embeddings instead of tf-idf values as done in the previous two tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d669ce-b652-462c-bf30-42092374e095",
   "metadata": {},
   "source": [
    "[Your answers here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7491ab1-d6cb-4bdd-a2ec-0e52dade8669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
