{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise Week 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the data [here](https://drive.google.com/file/d/1dpuJKyX6vvSRGDTiRRHsk5OChK23joRA/view?usp=share_link). Please do not hesitate to contact Xiaochen Zheng by [this email](mailto:xzheng@ethz.ch) if you have any question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to your data folder, where the data is saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mychvOTUu3sI",
    "outputId": "7358cf13-2f58-4017-e4cd-38940db3402e"
   },
   "outputs": [],
   "source": [
    "pwd = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a special package to load and investigate the dataset, the [pandas](https://pandas.pydata.org/docs/) library. Take a look at the documentation to see all the options!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MX-mQoHMu0Vc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # Package to load and investigate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg7B2PQX8GID"
   },
   "source": [
    "## Dataset description\n",
    "\n",
    "In this exercise, we want to design a machine learning/deep learning algorithm to help determine/predict whether a patient is non-diabetic (int `0`) or diabetic (int `1`). Each patient is identified with a unique patient ID (pid). In `full_data_train.csv`, medical, demographic, and diagnosis data for each patient is arranged in 20 consecutive rows. Research has identified the following as **important risk factors** for diabetes:\n",
    "\n",
    "```high blood pressure, high cholesterol, smoking, obesity, age and sex, race, diet, exercise, alcohol consumption, BMI, household income, marital status, sleep, time since last checkup, education, health care coverage, mental Health```\n",
    "\n",
    "Given these risk factors, we selected features from a open survey of diabetes related to these risk factors.\n",
    "\n",
    "\n",
    "### Features\n",
    "\n",
    "`Diabetes_binary`\n",
    "\n",
    "(Ever diagonsed) diabetes \n",
    "\n",
    "`HighBP` -> `Bool`\n",
    "\n",
    "High Blood Pressure\n",
    "\n",
    "`HighChol` -> `Bool`\n",
    "\n",
    "High Cholesterol\n",
    "\n",
    "`CholCheck` -> `Bool`\n",
    "\n",
    "Cholesterol check within past five years\n",
    "\n",
    "`BMI` -> `Float`\n",
    "\n",
    "Body Mass Index (BMI)\n",
    "\n",
    "`Smoker` -> `Bool`\n",
    "\n",
    "Have you smoked at least 100 cigarettes (5 packs) in your entire life? \n",
    "\n",
    "`Stroke` -> `Bool`\n",
    "\n",
    "(Ever diagosed) stroke. \n",
    "\n",
    "`HeartDiseaseorAttack` -> `Bool`\n",
    "\n",
    "Respondents that have ever reported having coronary heart disease (CHD) or myocardial infarction (MI)\n",
    "\n",
    "`PhysActivity` -> `Bool`\n",
    "\n",
    "Adults who reported doing physical activity or exercise during the past 30 days other than their regular job\n",
    "\n",
    "`Fruits` -> `Bool`\n",
    "\n",
    "Consume Fruit 1 or more times per day \n",
    "\n",
    "`Veggies` -> `Bool`\n",
    "\n",
    "Consume Vegetables 1 or more times per day \n",
    "\n",
    "`HvyAlcoholConsump` -> `Bool`\n",
    "\n",
    "Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week)\n",
    "\n",
    "`AnyHealthcare` -> `Bool`\n",
    "\n",
    "Do you have any kind of health care coverage, including health insurance, prepaid plans such as HMOs, or government plans such as Medicare, or Indian Health Service? \n",
    "\n",
    "`NoDocbcCost` -> `Bool`\n",
    "\n",
    "Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?\n",
    "\n",
    "`GenHlth` -> `Int`\n",
    "\n",
    "Would you say that in general your health is between 5 (highest) and 1 (lowest).\n",
    "\n",
    "`MentHlth` -> `Int`\n",
    "\n",
    "Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good? \n",
    "\n",
    "`PhysHlth` -> `Int`\n",
    "\n",
    "Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good? \n",
    "\n",
    "`DiffWalk` -> `Int`\n",
    "\n",
    "Do you have serious difficulty walking or climbing stairs? \n",
    "\n",
    "\n",
    "`Sex`, and `Age` -> `Int`\n",
    "\n",
    "`Education` -> `Int`\n",
    "\n",
    "This is already an ordinal variable with 1 being never attended school or kindergarten only up to 6 being college 4 years or more\n",
    "\n",
    "\n",
    "`Income` -> `Int`\n",
    "\n",
    "Variable is already ordinal with 1 being less than \\$10,000 all the way up to 8 being \\$75,000 or more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kksZugxTuYXv"
   },
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8wTKmJ1uXaY"
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "full_train = pd.read_csv(os.path.join(pwd, 'full_data_train.csv'))\n",
    "# Test dataset\n",
    "X_test = pd.read_csv(os.path.join(pwd, 'indicators_test.csv'))\n",
    "y_test = pd.read_csv(os.path.join(pwd, 'y_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyTpnXjqw647"
   },
   "source": [
    "### Check the raw data\n",
    "\n",
    "Use ```pandas.DataFrame.info``` to describe null values, data type, memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cDNf9U1vFHI",
    "outputId": "324a53d5-7a35-4c10-be59-5f6aa8eeb048"
   },
   "outputs": [],
   "source": [
    "full_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkr96I8jw86V",
    "outputId": "516c492f-3c81-4f7b-d890-dec70a48ede7"
   },
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sufPBth2xCG-"
   },
   "source": [
    "## Data Preprocessing\n",
    "Take a look at the raw data and think carefully about what kinds of data preprocessing methods needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoO8N_LWxJe-"
   },
   "outputs": [],
   "source": [
    "# You do not necessarily need to do anything here, this is just to provide some space to look at the dataset's properties and contents.\n",
    "\"*** YOUR CODE HERE. ***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Notice that there is one column name **PID** in both *full_train* and *X_test*. Why should we better remove this from the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    " Use the pandas `drop` function to remove the PID column in test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = ... # drop the PID column\n",
    "X_test = ... # drop the PID column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Separate the labels in the column `Diabetes_binary` from the training set and create a new tensor `y_train` and `y_test` containing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ... # drop Diabetes_binary column\n",
    "y_train = ... # use Diabetes_binary column as labels\n",
    "y_test = ... # use Diabetes_binary column as labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzHdDVFn6G-e"
   },
   "source": [
    "### Task 4 - Standardization Scaling\n",
    "Notice that different features have different scales. For example, `BMI` ranges from 12.0 to 98.0 and `Age` ranges from 1.0 to 13.0. Normalization is a data preparation technique that is frequently used in machine learning to deal with data with different scales.\n",
    "\n",
    "Here you will apply **standardization scaling**. The term **standardization** refers to the process of centering a variable at zero and standardizing the variance at one. Subtracting the mean of each observation and then dividing by the standard deviation is the procedure. The features will be rescaled so that they have the attributes of a typical normal distribution with standard deviations.\n",
    "\n",
    "***Hint***: Use `numpy` or `Standardscaler` provided by `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4QiZ88gxaj1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\"*** YOUR CODE HERE. ***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Data Structure\n",
    "By applying `pd.read_csv()`, you store your data in `pandas.DataFrame`. After finishing task 4, you should store your data in `numpy.ndarray`. But for `torch.nn.Module`, you need to transfer your data to the data type `torch.Tensor`.\n",
    "\n",
    "***Hint***: Try to learn and apply [torch.from_numpy()](https://pytorch.org/docs/stable/generated/torch.from_numpy.html), [torch.Tensor.to()](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html), [torch.tensor()](https://pytorch.org/docs/stable/generated/torch.tensor.html).\n",
    "\n",
    "Transform the variables `X_train`, `X_test`, `y_train` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\"*** YOUR CODE HERE. ***\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWnI2naSnBAE"
   },
   "source": [
    "## Deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Finish the deep learning skeleton step-by-step.\n",
    "\n",
    "***Hint***: \n",
    "\n",
    "(1) Implement a multilayer perceptron with several [linear layers](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) (e.g. 4 linear layers) followed by [relu activation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU). We show you an example of the first layer.\n",
    "\n",
    "(2) Take regularization into account and implement certain layers to avoid overfitting. e.g.\n",
    "\n",
    "(3) Make sure that the output's size of one layer should match the input's size of the following/subsequent layer by checking `tensor.shape`.\n",
    "\n",
    "(4) Make sure that your model's output should have the size of ($N$, 2), where $N$ is the batch size. 2 represents the possible outcome state of the model e.g. diabetic or non-diabetic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLD1xE4lvY55"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class YourModel(torch.nn.Module):\n",
    "    \"\"\" Your model should inherite from torch.nn.Module.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        self.fc1 = nn.Linear(21,64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass.'''\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        \"*** YOUR CODE HERE ***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        \n",
    "        # Perform forward pass\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        \n",
    "        # Compute loss\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        \n",
    "        # Perform backward pass\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        \n",
    "        # Perform optimization\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        \n",
    "        # Printing\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6u1Y64wWxHb"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "def main(train_data, train_label, test_data, test_label, batch_size, epochs):\n",
    "    \"\"\" Training your model.\n",
    "\n",
    "    Args:\n",
    "        train_data, test_data (tensor): The training/testing data. It should have a shape of (n_instance,aaaaaa n_features).\n",
    "        train_label, test_label (tensor): The labels of training/testing instances. It should have a shape of (n_instance, 1).\n",
    "        batch_size  (Union[int, NoneType]): The number of samples loaded for one iteration.\n",
    "        epochs (Union[int, NoneType]): The number of epochs. When this reaches, the training stops.\n",
    "    \"\"\"\n",
    "    # Set fixed random number seed. DO NOT CHANGE IT.\n",
    "    torch.manual_seed(336699)\n",
    "    \n",
    "    # Prepare series dataset.\n",
    "    train_dataset = \"*** YOUR CODE HERE. ***\" # TensorDataset()\n",
    "    train_loader = \"*** YOUR CODE HERE. ***\" # DataLoader()\n",
    "    test_dataset = \"*** YOUR CODE HERE. ***\" # TensorDataset()\n",
    "    test_loader = \"*** YOUR CODE HERE. ***\" # DataLoader()\n",
    "\n",
    "    # Initialize proposed model.\n",
    "    model = \"*** YOUR CODE HERE. ***\"\n",
    "\n",
    "    # Define the loss function and optimizer. You can freely choose your loss function and optimizer based on your task.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    criterion_test = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    # Run the training loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch}')\n",
    "\n",
    "        train(model, train_loader, criterion, optimizer, epoch)\n",
    "        test(model, test_loader, criterion_test)\n",
    "    \n",
    "    # Process is complete.\n",
    "    print('Training process has finished.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run your codes here.\n",
    "    main(train_data, train_label, test_data, test_label, batch_size, epochs) #exchange with your variabel names"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5940b77976ef3bac7cfc78a082ed4676e831584770ac5adf4c28bfa1611ecc43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
